\documentclass[conference]{IEEEtran}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{paralist}
\usepackage{tikz}
\usepackage[normalem]{ulem}

\providecommand{\e}[1]{\ensuremath{\times 10^{#1}}}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\title{Predicting Reciprocity in Social Networks}

\author{\IEEEauthorblockN{Anonymous}
\IEEEauthorblockA{Anonymous Department\\
Anonymous Institution \\
Anonymous Location \\
anon@whoare.you}
\and
\IEEEauthorblockN{Anonymous}
\IEEEauthorblockA{Anonymous Department\\
Anonymous Institution \\
Anonymous Location \\
anon@whoare.you}
\and
\IEEEauthorblockN{Anonymous}
\IEEEauthorblockA{Anonymous Department\\
Anonymous Institution \\
Anonymous Location \\
anon@whoare.you}}

% make the title area
\maketitle

\begin{abstract}
%\boldmath
In this paper we investigate methods of predicting reciprocity in social networks, and use machine learning and regression to determine good indicators of reciprocity. Using the Twitter @ message graph, we discover that the ratio of a node's outdegree to its indegree is the best predictor of reciprocity, and that heuristics used in link prediction do not necessarily perform well in reciprocity prediction. In fact, using only "degree/message" properties <<rephrase>> is sufficient in obtaining maximum accuracy.
\end{abstract}

% no keywords

% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\section{Introduction}
Reciprocity prediction and link prediction are inherently different problems - while link prediction is about predicting the occurence of rare events, reciprocity prediction predicts the "balance", or directions of an edge.

\subsection{Related work}
Tyler and Tang showed that reciprocity 
http://www.hpl.hp.com/research/idl/papers/rhythms/ECSCWFinal.pdf
To be written.

\subsection{Twitter as a domain to analyze}
Twitter is a good domain to explore the superposition of the reciprocated and unreciprocated networks. The reciprocated network consists of mainly mutual interactions between friends or people in the same social circle, while the unreciprocated network consists of interactions between individuals in different social circles. We can also relate these types of interactions to the concept of status - where people with similar status participate in reciprocal interactions (e.g. messages between friends), while those with dissimilar status participate in unreciprocal interactions (e.g. messages from fans to celebrities).

\subsection{Problem definition}
The input to our prediction problem is a graph $G=(V,E)$ and a node pair $\{v,w\}$, where $v,w \in V$ but all edges between $v$ and $w$ removed. Our task is to predict the direction of edges between $v$ and $w$.

Reciprocity prediction on this graph can be defined in two ways. In the first, given that at least one edge exists between $v$ and $w$, decide whether both $(v,w)$ and $(w,v)$ exist (bidirected/symmetric), or only one of $(v,w)$, $(w,v)$ exists (asymmetry). In the second, given an edge $(v,w)$, decide whether $(w,v)$ exists.

\subsection{Notation}

We subsequently consider the subgraphs of the form $G_n = (V_n, E_n)$, where $V_n = \{v~|~v \in V, v \text{ sent } \ge n \text{ messages}\}$ and $E_n = \{e=(v,w)~|~e \in E,~v \text{ and } w \in V_n\}$.

Also define \(v \xrightarrow{k} w$, which means $v$ sent $w$ $k$ messages. From this definition we can formalize reciprocity in terms of $k$. We define an edge $(v,w)$ to be reciprocated if $v \xrightarrow{k} w$ and $w \xrightarrow{k} v$, and unreciprocated if $v \xrightarrow{k} w$ and $w \xrightarrow{0} v$.

Let the set of reciprocated edges be \(E_k^r = \{ (v,w) : v \xrightarrow{k} w \text{ and } w \xrightarrow{k} v \} \), and the set of unreciprocated edges be \(E_k^u = \{ (v,w) : v \xrightarrow{k} w\} \).

Let $\deg^-(v)$ and $\deg^+(v)$ be the indegree and outdegree of node $v$ respectively, $\operatorname{msg}^-(v)$ and $\operatorname{msg}^+(v)$ be the messages received and sent by a node $v$, and $\Gamma^-(v) = \{w| (w,v) \in E\}$, or the set of people who send messages to $v$.

\section{Dataset description}
The sample dataset consisted of the directed @ message graph $G=(V,E)$ of the Twitter network from (TIME) to (TIME). 12,795,683 unique users ($|V|$) sent a total of 819,305,776 messages, with 156,868,257 unique directed interactions ($|E|$) taking place between users during this time.

In $G_{1000}$, $|E^r_{10}| = 797,342$, $|E^u_{10}| = 349,258$.

\section{Methods for Reciprocity Prediction}
Intuitively, features and measure whether $v$ and $w$ have similar status or a similar social circle, and each is potentially useful in predicting reciprocation. This section presents a survey of various methods that can be used in predicting reciprocity in networks. Each method assigns a value $\operatorname{val}(v,w)$ to a node pair $\{v,w\}$. Given values corresponding to all node pairs in question, we can then choose threshold values or ranges where we predict reciprocity, and non-reciprocity otherwise.

For each property, we picked a single value $\operatorname{val}_{OPT}$ for which we predict every edge with value lower than $\operatorname{val}_{OPT}$ is unreciprocated and reciprocated otherwise, or vice versa, to maximize prediction accuracy. Intuitively, we expect that larger values of each property correspond to a stronger indication of reciprocity. For example, a high mutual neighbor count for the nodes $v$ and $w$ could strongly indicate the existence of a reciprocated link between them.

We considered 4 different mechanisms of prediction: 
\begin{enumerate}
\item SYM (predicting symmetry), where we predict whether an edge is bidirectional or asymmetric after removing all information about the edge in question but using existing information about $v$ and $w$, 
\item REV (predicting a reverse edge), where we predict whether a reverse edge exists given that the forward edge $(v,w)$ exists using information about $v$ and $w$, and finally 
\item REV-$w$ (predicting a reverse edge using only $w$), where we predict whether a reverse edge exists given that $(v,w)$ exists, but only using information about $w$ in making that prediction.
\item REV-$v$ (predicting a reverse edge using only $v$), where we predict whether a reverse edge exists given that $(v,w)$ exists, but only using information about $v$ in making that prediction.
\end{enumerate}

\subsection{Degree/message features}
It seems intuitive that the relative indegree or outdegree of nodes would indicate whether a pair of nodes are in a one-sided or two-sided relationship. If both have a similar indegree, this might indicate that they are at a similar social status in the network. In contrast, a disproportionate indegree would indicate that one might be a celebrity and the other an average Joe, thus it would be unlikely that the relationship between them is reciprocated.

We also looked at their absolute counterparts (ex. indegree ratio of $v$ and $w$ to both the indegree of $v$ and the indegree to $w$) to see if these did better or worse on their own, compared to taking the ratio of both.

\emph{Indegree and outdegree ratio} both measure the ratio of outdegrees or indegrees of two nodes, and $\operatorname{val}(v,w) = \deg^-(v)/\deg^-(w)$ or $\deg^+(v)/\deg^+(w)$ respectively.

\emph{Inmessage and outmessage ratio} are similar, but instead also take into account the total number of messages that a node receives or sends, rather than the unique nodes that a node sends messages to or receives messages from.

\emph{Incoming message/indegree ratio and outgoing message/outdegree ratio} compares the ratio of two nodes' incoming message to indegree ratio or outgoing message to outdegree ratio. People with a high incoming message to indegree ratio might characterize people who have a small group of friends with which they exchange lots of messages, while those with a low incoming message to indegree ratio might characterize highly connected (and thus high-status) people in a network (as the messages they receive is "spread" over many more users).

\emph{Outdegree/indegree ratio} is a heuristic that attempts to characterize the messaging activity of a single node - a celebrity might have high outdegree/indegree ratio because she receive many messages from many followers but herself sends relatively few messages. We then characterize the ratio of the outdegree/indegree ratio of two nodes, or $\operatorname{val}(v,w) = \frac{\deg^+(v)}{\deg^-(v)} / \frac{\deg^+(w)}{\deg^-(w)}$.

\subsection{Link prediction features}
It is not intuitive whether methods that work well for link prediction would work well in reciprocity; while link prediction asks whether an edge could exist between two nodes, reciprocity prediction asks whether a known edge is bidirectional.

\emph{Mutual neighbors} calculates the number of common people whom $v$ and $w$ both send messages to ($|\Gamma^+(v) \cap \Gamma^+(w)|$), or the number of people who send messages to both $v$ and $w$ ($|\Gamma^-(v) \cap \Gamma^-(w)|$).

\emph{Jaccard's coefficient}, also based on the concept of mutual neighbors, calculates the similarity between two sets by taking the ratio of the cardinality of their intersection and their union. $\operatorname{val}(v,w) = \frac{|\Gamma^-(v) \cap \Gamma^-(w)|}{|\Gamma^-(v) \cup \Gamma^-(w)|}$.

\emph{Adamic and Adar} \cite{Adamic:2003ud}, defined the similarity between web sites $v,w$ to be $ \sum_{\{x|v,w \text{ share feature }x\}} \frac{1}{\log{\text{frequency}(x)}} $, and we similarly define $\operatorname{val}(v,w)$ to be \[ \sum_{\{x|x \in \Gamma^-(v) \cap \Gamma^-(w)\}} \frac{1}{\log{\deg^-(x)}} .\]

\emph{Preferential attachment} is another popular heuristic in modeling network growth, where the probability that an edge forms with a specific node is proportional to its existing indegree. Here, $\operatorname{val}(v,w) = \deg^-(v)\cdot \deg^+(w)$, or $\deg^+(v)\cdot \deg^-(w)$.

\emph{2 step paths (ratio)} is a simplification of what Katz \cite{Katz:1953un} developed as a measure of status by calculating the number of paths between two nodes. In this study, we only consider paths of length 2, and $\operatorname{val}(v,w) = \operatorname{paths}^2(v,w)|$, where $\operatorname{paths}^2(v,w)$ is the set of paths from $v$ to $w$ of length $2$. The 2 step paths ratio is simply the ratio of number of two step paths from $v$ to $w$ to that from $w$ to $v$. 

TODO I can also calculate that in the case where you predict a reverse edge, you use the path from $v$ to $w$ in your calculation, thus adding a single on-step path to the calculation.

\subsection{Different sets of features}
For convenience, we further break down these two sets of features into four sets:
\begin{enumerate}
	\item Absolute degree/message features - degree, messages, message-degrees, outdegree-indegrees
	\item Relative degree/message features - degree ratios, message ratios, message-degree ratios, and outdegree-indegree ratios
	\item Two-step hop features - mutual neighbors (in and out), and two step paths ($v$ to $w$ and $w$ to $v$)
	\item Link prediction features - all other link prediction features not mentioned
\end{enumerate}

\subsection{Two-step hops}
\begin{figure}[!t]
\centering
\caption{Two-step hops}
\label{fig_2step}
\subfloat[2-step ($v$ to $w$)]{
\begin{tikzpicture}[shorten >=1pt,->]
  \tikzstyle{vertex}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]

  \foreach \name/\x in {v/1, ?/2, w/3}
    \node[vertex] (G-\name) at (\x,0) {$\name$};

  \foreach \from/\to in {v/?, ?/w}
    \draw (G-\from) -- (G-\to);

\end{tikzpicture}}\quad
\subfloat[2-step ($w$ to $v$)]{
\begin{tikzpicture}[shorten >=1pt,->]
  \tikzstyle{vertex}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]

  \foreach \name/\x in {v/1, ?/2, w/3}
    \node[vertex] (G-\name) at (\x,0) {$\name$};

  \foreach \from/\to in {w/?, ?/v}
    \draw (G-\from) -- (G-\to);

\end{tikzpicture}}
\\
\subfloat[Mutual (in)]{
\begin{tikzpicture}[shorten >=1pt,->]
  \tikzstyle{vertex}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]

  \foreach \name/\x in {v/1, ?/2, w/3}
    \node[vertex] (G-\name) at (\x,0) {$\name$};

  \foreach \from/\to in {?/w, ?/v}
    \draw (G-\from) -- (G-\to);

\end{tikzpicture}}\quad
\subfloat[Mutual (out)]{
\begin{tikzpicture}[shorten >=1pt,->]
  \tikzstyle{vertex}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]

  \foreach \name/\x in {v/1, ?/2, w/3}
    \node[vertex] (G-\name) at (\x,0) {$\name$};

  \foreach \from/\to in {w/?, v/?}
    \draw (G-\from) -- (G-\to);

\end{tikzpicture}}
\end{figure}
The importance of "friends of friends" or people 2 hops away from a given node lends itself to exploring features that directly arise out of the directed @-message graph. There are essentially four types of two-step hops, as shown in figure \ref{fig_2step}, which correspond to either the number of common in-neighbors or out-neighbors (mutual neighbors), or the number of directed paths from $v$ to $w$ or vice versa (two-step paths). 

If both $v$ and $w$ send messages to many common people, it is likely that they are in the same social circle, or it could be that they just like the same celebrities. If $v$ and $w$ receive many messages from the same group of people, it could be that both $v$ and $w$ are in the same community, or that both $v$ and $w$ are celebrities (who may or may not talk to each other) and there is an overlapping fanbase.

As the number of paths from $v$ to $w$ increases, there are two conflicting forces of $w$ being popular and thus it unlikely for $w$ to reciprocate an edge from $v$ to $w$. The reverse case is simpler -- as the number of paths from $w$ to $v$ increases, intuitively the likelihood that $w$ knows $v$ is a lot higher.

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Reciprocity Prediction Features}
\label{table_recmethods}
\centering
\begin{tabular}{|c||c|}
\hline
\bf{Feature} & $\mathbf{val}(v)$ or $\mathbf{val}(v,w)$\\
\hline
\multicolumn{2}{|c|}{\emph{Absolute degree/message features}} \\
\hline
Indegree or outdegree & $\deg^-(v)$ or $\deg^+(v)$ \\
Incoming or outgoing messages & $\operatorname{msg}^-(v)$ or $\operatorname{msg}^+(v)$ \\
Message-degree (in or out) & $\frac{\operatorname{msg}^-(v)}{\deg^-(v)}$ or $\frac{\operatorname{msg}^+(v)}{\deg^+(v)}$ \\
Outdegree-indegree & $\frac{\deg^+(v)}{\deg^-(v)}$ \\
\hline
\multicolumn{2}{|c|}{\emph{Relative degree/message features}} \\
\hline
Indegree ratio & $\deg^-(v) / \deg^-(w)$ \\
Outdegree ratio & $\deg^+(v) / \deg^+(w)$ \\
\hline
Incoming message ratio & $\operatorname{msg}^-(v) / \operatorname{msg}^-(w)$ \\
Outgoing message ratio & $\operatorname{msg}^+(v) / \operatorname{msg}^+(w)$ \\
\hline
Message-degree ratio (in) & $\frac{\operatorname{msg}^-(v)}{\deg^-(v)} / \frac{\operatorname{msg}^-(w)}{\deg^-(w)}$ \\
Message-degree ratio (out) & $\frac{\operatorname{msg}^+(v)}{\deg^+(v)} / \frac{\operatorname{msg}^+(w)}{\deg^+(w)}$ \\
\hline
Outdegree-indegree ratio & $\frac{\deg^+(v)}{\deg^-(v)} / \frac{\deg^+(w)}{\deg^-(w)} $ \\
\hline
\multicolumn{2}{|c|}{\emph{Link prediction features}} \\
\hline
Mutual neighbors (in) & $|\Gamma^-(v) \cap \Gamma^-(w)|$ \\
Mutual neighbors (out) & $|\Gamma^+(v) \cap \Gamma^+(w)|$ \\
\hline
Jaccard's coefficient (in) & $\frac{|\Gamma^-(v) \cap \Gamma^-(w)|}{|\Gamma^-(v) \cup \Gamma^-(w)}$ \\
Jaccard's coefficient (out) & $\frac{|\Gamma^+(v) \cap \Gamma^+(w)|}{|\Gamma^+(v) \cup \Gamma^+(w)}$ \\
\hline
Adamic/Adar & $\sum_{\{x|x \in \Gamma^-(v) \cap \Gamma^-(w)\}} \frac{1}{\log{\deg^-(x)}}$ \\
\hline
Preferential attachment ($v$ to $w$) & $\deg^+(v)\cdot \deg^+(w)$ \\
Preferential Attachment ($w$ to $v$) & $\deg^-(v)\cdot \deg^-(w)$ \\
\hline
Two-step paths ($v$ to $w$) & $ |\operatorname{paths}^2(v,w)|$ \\
Two-step paths ($w$ to $v$) & $ |\operatorname{paths}^2(w,v)|$ \\
\hline
Two-step paths ratio & $\frac{|\operatorname{paths}^2(v,w)|}{|\operatorname{paths}^2(w,v)|}$ \\
% $\frac{\sum_{i=1}^2 \beta^i|\operatorname{paths}^i(v,w)|}{\sum_{i=1}^2 \beta^i|\operatorname{paths}^i(w,v)|}$ Did badly
\hline
\end{tabular}
\end{table}

\section{Results and Discussion}

\subsection{Individual properties}
To calculate the accuracy of the individual heuristics, we calculated the values obtained for each method on a subset of $E_{10}^r \cup E_{10}^u$ of the graph $G_{1000}$, where equal numbers of edges were taken from the two sets of reciprocated and unreciprocated edges. The baseline accuracy is 0.500, since you would achieve this by simply predicting that all edges were of one type.

We then picked a threshold value $\operatorname{val}_{OPT}$ to optimize prediction accuracy, where we would predict reciprocity above the threshold, and non-reciprocity otherwise (or vice versa). Tables \ref{table_recresults_indiv} and \ref{table_recresults_indivVW} summarize the performance of each heuristic on the subgraph $G_{1000}, k=10$, while table \ref{table_recresults_indeg} summarizes the different mechanisms of prediction for a single heuristic. 

\subsubsection{Comparison of mechanisms of prediction}

In table \ref{table_recresults_indeg}, SYM$^+$ refers to the prediction mechanism where we aim to predict symmetry and predict all edges with values \emph{above} $val_{OPT}$ to be reciprocated, and REV$^-$ refers to the mechanism where we aim to predict whether a reverse edge $(w,v)$ exists given $(v,w)$ and predict all edges with values \emph{below} $val_{OPT}$ to be reciprocated. 

We observe slightly higher accuracy for the REV task than SYM, as REV is ``easier" than SYM since you know more information about the edge $(v,w)$.

Comparing REV-$v$ to REV-$w$, we see REV-$w$ performing better than REV-$v$, since we're trying to predict the existence of the edge from $w$ to $v$ given $(v,w)$, and it would appear that knowing about $w$ is a lot more valuable than knowing about $v$.

Note that SYM$^-$, REV$^-$, REV$-w^+$ and REV-$v^-$ do so poorly that simply predicting that everything was reciprocated (or unreciprocated) would do better.

\subsubsection{Comparison of methods of prediction}
\paragraph{Trends}
On the whole, outdegree-indegree ratio and the two-step paths ratio are the best indicators of reciprocity.

\paragraph{Larger is better?}
When we look at features using one of the four mechanisms, the larger the value, the more likely it is for reciprocation to occur, and this is the case for a majority of features. For example, a 
However,
TODO Two-step paths $v$ to $w$.
TODO Preferential attachment both ways.

\paragraph{REV-$v$ vs. REV-$w$}
Not surprisingly, REV-$w$ performs better than REV-$v$ on almost all features, and where REV-$v$ performs better, the difference is not as significant. Analagous to whether you would want to know more about the features of a marketer ($v$) vs. a subscriber ($w$), knowing about the subscriber tells us more about the relationship between both.

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Indegree performance - different methods}
\label{table_recresults_indeg}
\centering
\begin{tabular}{|c||c|c|}
\hline
\bf{Mechanism} & $\mathbf{val}_{OPT}$ (Percentile) & \bf{Accuracy} \\
\hline
\multicolumn{3}{|c|}{\emph{Indegree ratio}} \\
\hline
SYM$^+$ & 0.256 (40) & 0.702 \\
SYM$^-$ & - & - \\
REV$^+$ & 0.414 (46) & 0.759 \\
REV$^-$ & - & - \\
\hline
\multicolumn{3}{|c|}{\emph{Indegree of $v$ or $w$}} \\
\hline
REV-$w^+$ & - & - \\
REV-$w^-$ & 74 (61) & 0.731 \\
REV-$v^+$ &  61 (60) & 0.582 \\
REV-$v^-$ & - & - \\
\hline
\end{tabular}
\end{table}

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Reciprocity Prediction Method Performance: Individual (REV)}
\label{table_recresults_indiv}
\centering
\begin{tabular}{|c||c|c|}
\hline
\bf{Method} & $\mathbf{val}_{OPT}$ (Percentile) & \bf{Accuracy} \\
\hline
Indegree ratio & 0.414 (46) & 0.759 \\
Outdegree ratio & 0.667 (43) & 0.628 \\
\hline
Incoming message ratio & 0.333 (48) & 0.772 \\
Outgoing message ratio & 0.905 (46) & 0.547 \\
\hline
Incoming message-indegree ratio & 0.650 (39) & 0.569 \\
Outgoing message-outdegree ratio & 0.791 (33) & 0.615* \\
\hline
Outdegree-indegree ratio & 1.72 (53) & 0.820* \\
\hline
Mutual neighbors (in) & 10 (61) & 0.552 \\
Mutual neighbors (out) & 8 (51) & 0.580 \\
\hline
Jaccard's coefficient (in) & 0.0345 (48) & 0.684 \\
Jaccard's coefficient (out) & 0.0637 (55) & 0.660 \\
\hline
Adamic/Adar & 1.94 (55) & 0.561 \\
\hline
Two-step paths ($v$ to $w$) & 6 (59) & 0.517* \\
Two-step paths ($w$ to $v$) & 5 (51) & 0.657 \\
Two-step paths ratio (directed) & 0.556 (52) & 0.760 \\
Two-step paths ratio (undirected) & 0.259 (34) & 0.516 \\
\hline
Preferential attachment ($v$ to $w$) & 10230 (58) & 0.687* \\
Preferential attachment ($w$ to $v$) & 2610 (37) & 0.534* \\
\hline
\end{tabular}
\end{table}

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Reciprocity Prediction Method Performance: Individual (REV-$v$,REV-$w$)}
\label{table_recresults_indivVW}
\centering
\begin{tabular}{|c||c|c|}
\hline
\bf{Method} & $\mathbf{val}_{OPT}$ (Percentile) & \bf{Accuracy} \\
\hline
Indegree (v) &  61 (60) & 0.582 \\
Indegree (w) & 148 (61) & 0.731* \\
Outdegree (v) & 25 (14) & 0.506* \\
Outdegree (w) & 105 (60) & 0.647* \\
\hline
Incoming messages (v) & 619 (53) & 0.637 \\
Incoming messages (w) & 1802 (54) & 0.733* \\
Outgoing messages (v) & 906 (51) & 0.542 \\
Outgoing messages (w) & 506 (17) & 0.524* \\
\hline
Incoming message-indegree (v) & 9.4 (41) & 0.596 \\
Incoming message-indegree (w) & 9.12 (30) & 0.535 \\
Outgoing message-outdegree (v) & 13.2 (50) & 0.523 \\
Outgoing message-outdegree (w) & 8.14 (36) & 0.661 \\
\hline
Outdegree-indegree (v) & 1.28 (53) & 0.679* \\
Outdegree-indegree (w) & 0.747 (50) & 0.777 \\
\hline
\end{tabular}
\end{table}

\subsection{Decision tree analysis}

We then combined subsets of features and evaluated their performance, by splitting the edges in $E^r_10 \cup E_10^u$ randomly into two sets, training on one and evaluating on the other.

The following combined subsets, in addition to each individual subset, were considered:
\begin{enumerate}
	\item {\bf All} (sets 1-4) -- every single feature was considered.
	\item {\bf All ratio} (sets 2,3,4) -- all features that used ratios were considered.
	\item {\bf All absolute} (sets 1,3,4) -- we wanted to see how using "absolute" features would affect our decision accuracy.
\end{enumerate}
\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Decision Tree Accuracy}
\label{table_recresults_dtree}
\centering
\begin{tabular}{|c||c|c|}
\hline
\bf{Set} & Accuracy & Top-level attribute \\
\hline
Degree/message (1) & 0.828 & Outdegree-indegree (w) \\
Degree/message ratio (2) & 0.861 & Outdegree-indegree ratio \\
Two step hops (3) & 0.795 & Two-step paths ($w$ to $v$) \\
Link prediction (4) & 0.742 & Two-step paths ratio (directed) \\
\hline
\multicolumn{3}{|c|}{\emph{Combined}} \\
\hline
All ratio (2,3,4) & 0.861 & Outdegree-indegree ratio \\
All absolute (1,3,4) & 0.828 & Outdegree-indegree (w) \\
All (1-4) & 0.861 & Outdegree-indegree ratio \\
\hline
\end{tabular}
\end{table}

We notice that the accuracy when we only use degree/message features compared to that when we include all features is the same. 

Whenever the outdegree-indegree value or ratio was included as an attribute, it became the most important.

\subsection{Regression analysis}
We used a logistic regression model on subsets of features as well, where $f(z) = \frac{e^z}{e^z+1}$ and $z = \beta_0 + \beta F$, where $f(z)$ is binary and takes the value 1 when an edge is reciprocated, and 0 otherwise. $F$ is the vector of features.

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Logistic regression -- relative degree/message-based features}
\label{table_recresults_logr}
\centering
\begin{tabular}{|c||c|c|}
\hline
\bf{Feature} & $\mathbf{\beta}$ & $\mathbf{p}$ value \\
\hline
Indegree ratio & 0.0101903 & $< 2 \e{-16} $ \\
Outdegree ratio & 0.0005775 & \sout{0.2545} \\
Incoming messages ratio & 0.0230161 & $< 2 \e{-16} $ \\
Outgoing messages ratio & -0.0047152 & $< 2 \e{-16} $ \\
Incoming messages-indegree ratio & -0.0005545 & \sout{0.0798} \\
Outgoing messages-outdegree ratio & -0.0049387 & $< 2 \e{-16} $ \\
Outdegree-indegree ratio & \bf{-0.0562983} & $< 2 \e{-16} $ \\
\hline
\end{tabular}
\end{table}

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Logistic regression -- two-step hop features}
\label{table_recresults_logrpath}
\centering
\begin{tabular}{|c||c|c|}
\hline
\bf{Feature} & $\mathbf{\beta}$ & $\mathbf{p}$ value \\
\hline
Mutual neighbors (in) & -0.0117269 & $< 2 \e{-16} $ \\
Mutual neighbors (out) & 0.0180579 & $< 2 \e{-16} $ \\
Two-step paths ($v$ to $w$) & -0.1193624 & $< 2 \e{-16} $ \\
Two-step paths ($w$ to $v$) & 0.1296081 & $< 2 \e{-16} $ \\
\hline
\end{tabular}
\end{table}

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Logistic regression -- All ratio}
\label{table_recresults_lograll2}
\centering
\begin{tabular}{|c||c|c|}
\hline
\bf{Feature} & $\mathbf{\beta}$ & $\mathbf{p}$ value \\
\hline
Indegree ratio     &    0.0120256  & $< 2 \e{-16} $\\
Outdegree ratio    &   -0.0015554  & 0.005739 \\
Incoming messages ratio    &    0.0145437  & $< 2 \e{-16} $\\
Outgoing messages ratio   &   -0.0043189  & $< 2 \e{-16} $\\
Incoming messages-indegree ratio   & 0.0048525   & $< 2 \e{-16} $ \\
Outgoing messages-outdegree ratio   & -0.0046674 & $< 2 \e{-16} $ \\
Outdegree-indegree ratio  &  -0.0301592  & $< 2 \e{-16} $\\
\hline
Mutual Neighbors (in) & -0.0279290  &$< 2 \e{-16} $\\
Mutual Neighbors (out) & 0.0147103  & $< 2 \e{-16} $\\
Two-step paths ($v$ to $w$)  &  \bf{-0.0530463}   & $< 2 \e{-16} $\\
Two-step paths ($w$ to $v$)   &    0.0182572   & $< 2 \e{-16} $\\
\hline
Two-step paths (directed)  &   \bf{0.0394657} & $< 2 \e{-16} $\\
Jaccard (in) & -0.0238541 & $< 2 \e{-16} $\\
Jaccard (out) &   \bf{0.0572358}  & $< 2 \e{-16} $\\
Adamic-Adar  &    -0.0001424 & \sout{0.881637} \\
Preferential attachment ($v$ to $w$) & 0.0010837  & 0.000627 \\
Preferential attachment ($w$ to $v$)  &  - & -  \\
\hline
\end{tabular}
\end{table}

\begin{table}[!t]
\renewcommand{\arraystretch}{1.3}
\caption{Logistic regression - All}
\label{table_recresults_lograll3}
\centering
\begin{tabular}{|c||c|c|}
\hline
\bf{Feature} & $\mathbf{\beta}$ & $\mathbf{p}$ value \\
\hline
Indegree ratio     &    0.0041791  & $6.09\e{-8}$  \\
Outdegree ratio    & 0.0046914 & $1.28\e{-13}$ \\
Incoming messages ratio    &   0.0029794  & 0.000125 \\
Outgoing messages ratio   &   0.0033361  & $3.10\e{-10}$ \\
Incoming messages-indegree ratio & 0.0040884 &  $1.11\e{-14}$ \\
Outgoing messages-outdegree ratio &  -0.0015075 &  0.006283 \\
Outdegree-indegree ratio  &   -0.0057958 & $< 2 \e{-16} $\\
\hline
Indegree (v) & 0.0050520 & $ 4.30 \e{-11}$ \\
Indegree (w) & -0.0089197 & $<2 \e{-16} $ \\
Outdegree (v) & -0.0063247 & $<2 \e{-16}$ \\
Outdegree (w) & 0.0035881 & $3.58\e{-7}$ \\
Incoming messages (v) & 0.0063390 & $<2 \e{-16} $ \\
Incoming messages (w) & -0.0179975 & $<2 \e{-16} $ \\
Outgoing messages (v) & -0.0070869 & $<2 \e{-16} $\\
Outgoing messages (w) & 0.0095572 & $<2 \e{-16} $ \\
Incoming message-indegree (v) & -0.0023250 & $1.11\e{-5}$ \\
Incoming message-indegree (w) & -0.0004044 & \sout{0.42781} \\
Outgoing message-outdegree (v) & 0.0007430 & \sout{0.175454}  \\
Outgoing message-outdegree (w) & 0.0024155 & $2.54\e{-5}$ \\
Outdegree-indegree (v) & -0.0110324 & $<2 \e{-16} $ \\
Outdegree-indegree (w) & 0.0218874 & $<2 \e{-16} $ \\
\hline
Mutual Neighbors (in) &-0.0194635  &$< 2 \e{-16} $\\
Mutual Neighbors (out) &0.0050245  & $< 2 \e{-16} $\\
Two-step paths ($v$ to $w$)  &  -0.0462950   & $< 2 \e{-16} $\\
Two-step paths ($w$ to $v$)   &    0.0167156  & $< 2 \e{-16} $\\
\hline
Two-step paths (directed)  &   0.0440107 & $< 2 \e{-16} $\\
Jaccard (in) & -0.0398243 & $< 2 \e{-16} $\\
Jaccard (out) &   0.0561815  & $< 2 \e{-16} $\\
Adamic-Adar  & 0.0111504 & $< 2 \e{-16} $ \\
Preferential attachment ($v$ to $w$) & 0.0009537 & 0.003002 \\
Preferential attachment ($w$ to $v$)  &  - & -  \\
\hline
\end{tabular}
\end{table}

\section{Twitter as a superposition of networks}

\subsection{(Un)reciprocated subgraph analysis}
We also analyzed how various properties of the subgraphs $G_n$, as well as the edge sets $E^r_k$ and $E^u_k$ varied as we adjusted $n$ and $k$.

\paragraph{Reciprocated and unreciprocated edges} we notice that the frequency of reciprocated edges is approximately 2 to 3 times that of unreciprocated edges, and the proportion of reciprocated edges increases as $n$ and $k$ increases (Fig. \ref{fig_rur_propne}). While reciprocated communication is the dominant form of interaction, we see a significant number of "unreciprocated" interaction, indicating that a significant number of relationships on Twitter are unbalanced. This could occur when a user of lower status tries to get the attention of a more influential user (of higher status) by messaging him or her (e.g. when a fan messages a celebrity multiple times hoping to get a reply). 

\paragraph{Reciprocated and unreciprocated nodes} a majority of nodes have reciprocated relationships, with a small proportion having only unreciprocated relationships. A significant proportion of nodes take part in both reciprocated and unreciprocated relationships - indicating that while there are two distinct types of relationships occuring on Twitter, this does not correspond to two distinct types of users. A reason that "unreciprocated" Twitter users are not common might be that social, and hence reciprocated relationships are the driving factor of active, continued use of the platform. 

We can also see this in Fig. \ref{fig_rur_sca2}, a scatter plot of the number of users with each of 3 types of interaction - 1 reciprocated and 2 unreciprocated, as an unreciprocal interaction is by definition asymmetric. We differentiate between both ends in an unreciprocated edge ($v \xrightarrow{k} w$ and $w \xrightarrow{0} v$), where where a user could be $v$ if she's not replied to, or $w$ if she doesn't reply. The most common type of nodes are those which only have reciprocated edges, with a lot less having some unreciprocal interactions of some type.

\paragraph{Clustering coefficient remains relatively stable as $n$, $k$ vary, and the graphs corresponding to $E_k^r$ and $E_k^u$ are connected} this demonstrates that the network properties of these subgraphs do not change significantly even if we sample from a relatively smaller population of all users (Fig. \ref{fig_rur_cc},\ref{fig_rur_lcc}).

\begin{figure}[!t]
\centering
\subfloat[Varying $n$]{\includegraphics[width=1.5in]{proportion_edgesnodes_n}}                
\subfloat[Varying $k$]{\includegraphics[width=1.5in]{proportion_edgesnodes_k}}
\caption{Proportion of nodes or edges}
\label{fig_rur_propne}
\end{figure}

\begin{figure}[!t]
\centering
\subfloat[Varying $n$]{\includegraphics[width=1.5in]{average_clustering_n}}                
\subfloat[Varying $k$]{\includegraphics[width=1.5in]{average_clustering_k}}
\caption{Clustering coefficient}
\label{fig_rur_cc}
\end{figure}

\begin{figure}[!t]
\centering
\subfloat[Varying $n$]{\includegraphics[width=1.5in]{proportion_largestcc_n}}                
\subfloat[Varying $k$]{\includegraphics[width=1.5in]{proportion_largestcc_k}}
\caption{Proportion in largest connected component}
\label{fig_rur_lcc}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=2.5in]{scatter3}
\caption{Scatter plot of users' interaction types}
\label{fig_rur_sca2}
\end{figure}

% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command, the
% \label for the overall figure must come after \caption.
% \hfil must be used as a separator to get equal spacing.
% The subfigure.sty package works much the same way, except \subfigure is
% used instead of \subfloat.
%
%\begin{figure*}[!t]
%\centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
%\label{fig_second_case}}}
%\caption{Simulation results}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.

\section{Conclusion}
To be written.


\section*{Acknowledgment}
The authors would like to thank Twitter for providing our experimental dataset. This work was supported by (SOMEGRANT).


\bibliographystyle{IEEEtran}
\bibliography{rec}

\end{document}


